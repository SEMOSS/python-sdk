{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI Server SDK for Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ai-server-sdk in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (0.0.19)\n",
      "Requirement already satisfied: requests in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from ai-server-sdk) (2.32.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from ai-server-sdk) (2.2.3)\n",
      "Requirement already satisfied: jsonpickle in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from ai-server-sdk) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from pandas->ai-server-sdk) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from pandas->ai-server-sdk) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from pandas->ai-server-sdk) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from pandas->ai-server-sdk) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests->ai-server-sdk) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests->ai-server-sdk) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests->ai-server-sdk) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from requests->ai-server-sdk) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->ai-server-sdk) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~angchain (c:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade ai-server-sdk\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Server Connection & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Server Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Am I connected to the server? True\n",
      "This is my current insight ID: 8df5f2aa-b48b-4008-bfec-4fb5b3ce8e4a\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ai_server import ServerClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../.env')\n",
    "SECRET_KEY = os.getenv('DEV_SECRET_KEY')\n",
    "ACCESS_KEY = os.getenv('DEV_ACCESS_KEY')\n",
    "\n",
    "# Here we connect to the demo instance of CFG, but you would connect to your own instance\n",
    "connection_url = 'https://workshop.cfg.deloitte.com/cfg-ai-dev/Monolith/api'\n",
    "\n",
    "# This object creates a connection to the CFG server\n",
    "server_connection = ServerClient(base = connection_url, access_key = ACCESS_KEY, secret_key = SECRET_KEY)\n",
    "\n",
    "# Check if you are connected to the server\n",
    "is_connected = server_connection.connected\n",
    "print(f\"Am I connected to the server? {is_connected}\")\n",
    "\n",
    "# Initilizing the server creates a new insight which is accessible through .cur_insight\n",
    "my_insight = server_connection.cur_insight\n",
    "print(f\"This is my current insight ID: {my_insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My current insight is now: 5ec12e9a-1578-4303-a015-49d65dc3fa4e\n"
     ]
    }
   ],
   "source": [
    "# You can create new insights by calling the .make_new_insight() method\n",
    "new_insight = server_connection.make_new_insight() # This becomes your active insight\n",
    "\n",
    "print(f\"My current insight is now: {server_connection.cur_insight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing open insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are my open insights: ['5ec12e9a-1578-4303-a015-49d65dc3fa4e', '8df5f2aa-b48b-4008-bfec-4fb5b3ce8e4a']\n"
     ]
    }
   ],
   "source": [
    "my_open_insights = server_connection.get_open_insights()\n",
    "\n",
    "print(f\"These are my open insights: {my_open_insights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping insights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are my insight IDs after dropping: ['3ace0467-9956-46c8-ae16-94f851e9f3da']\n"
     ]
    }
   ],
   "source": [
    "# You can drop all of your insights with the .drop_insights() method and passing in the list of insights\n",
    "# Here we drop all of our open insight ids \n",
    "server_connection.drop_insights(my_open_insights) # This will create a new insight id since there must be an active insight\n",
    "\n",
    "print(f\"Here are my insight IDs after dropping: {server_connection.get_open_insights()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python trick to check attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the attributes of the server connection object: ['access_key', 'auth_headers', 'bearer_token', 'bearer_token_provider', 'connected', 'cookies', 'cur_insight', 'da_server', 'drop_insights', 'get_auth_headers', 'get_open_insights', 'get_openai_endpoint', 'get_partial_responses', 'get_pixel_output', 'import_data_product', 'loginBearerToken', 'loginUserAccessKey', 'logout', 'main_url', 'make_new_insight', 'monitors', 'open_insights', 'r', 'run_pixel', 'run_pixel_separate_thread', 'secret_key', 'send_request', 'upload_files']\n"
     ]
    }
   ],
   "source": [
    "attributes = dir(server_connection)\n",
    "# Find all of the attributes available to the server connection object\n",
    "attributes = [attr for attr in attributes if not attr.startswith('__')]\n",
    "\n",
    "print(f\"Here are the attributes of the server connection object: {attributes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModelEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They both weigh the same, 1 pound. The difference lies in their density and volume. A pound of feathers would occupy a larger volume than a pound of bricks due to the difference in their densities.\n",
      "We also get acess to: \n",
      "messageId: 952e8e77-32d2-4bb8-a4bc-9ba1230d894d\n",
      "roomId: 3ace0467-9956-46c8-ae16-94f851e9f3da\n",
      "numberOfTokensInPrompt 12\n",
      "numberOfTokensInResponse 36\n"
     ]
    }
   ],
   "source": [
    "from ai_server import ModelEngine\n",
    "\n",
    "# An ID for the specific LLM you want to interact with\n",
    "engine_id = os.getenv('DEV_LLM_CHAT_ENGINE_ID')\n",
    "\n",
    "# We need to pass the engine id and an insight id to the ModelEngine object\n",
    "llama3_model = ModelEngine(engine_id=engine_id, insight_id = server_connection.cur_insight)\n",
    "\n",
    "question = \"What weighs more, a pound of feathers or a pound of bricks?\"\n",
    "\n",
    "# The ask method sends a question to the model and returns the response\n",
    "try:\n",
    "    answer = llama3_model.ask(question)\n",
    "except Exception as e:\n",
    "    print(f\"An error occured: {e}\")\n",
    "\n",
    "print(answer['response'])\n",
    "\n",
    "print(\"We also get acess to: \")\n",
    "print(f\"messageId: {answer['messageId']}\")\n",
    "print(f\"roomId: {answer['roomId']}\")\n",
    "print(f\"numberOfTokensInPrompt\", answer['numberOfTokensInPrompt'])\n",
    "print(f\"numberOfTokensInResponse\", answer['numberOfTokensInResponse'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Inferencing with parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They weigh the same, 1 pound. The feathers will take up more space than the bricks because feathers are very light and take up a lot of room, but they both weigh the same.\n"
     ]
    }
   ],
   "source": [
    "# We can add parameters to our requests such as context, history, max_new_tokens, repetition_penalty, seed, temperature, top_k, top_p, truncate, typical_p\n",
    "params = {\n",
    "    \"temperature\": 0.9, \n",
    "    \"max_new_tokens\": 200,\n",
    "    \"context\": \"You are a first grade teacher that uses language and explanations easy for children to understand.\"\n",
    "    }\n",
    "\n",
    "# Pass your parameters as a dictionary to the ask method using the param_dict argument\n",
    "new_answer = llama3_model.ask(question, param_dict=params)\n",
    "\n",
    "print(new_answer['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's dive deeper into the concept of density and weight. Density is defined as the mass per unit volume of a substance. In the case of the feather and the brick, they both weigh 1 pound, which means they have the same mass.\n",
      "\n",
      "However, the density of a feather is much lower than that of a brick. Feathers are essentially made up of air, which is very light. As a result, a large volume of feathers weighs the same as a small volume of bricks. This is why a pound of feathers takes up more space than a pound of bricks.\n",
      "\n",
      "To quantify this, let's consider some approximate densities. The density of feathers is around 0.07-0.1 g/cm³, while the density of bricks is around 2-3 g/cm³. This means that for every cubic centimeter of feathers, you would need to have only about 0.07-0.1 grams to match the weight of a cubic centimeter of bricks.\n",
      "\n",
      "Using these values, let's calculate the volume of a pound of feathers and a pound of bricks. Assuming a density of 0.09 g/cm³ for feathers, we can calculate the volume of a pound of feathers as follows:\n",
      "\n",
      "1 pound = 453.59 grams\n",
      "453.59 grams / 0.09 g/cm³ = approximately 5049 cm³\n",
      "\n",
      "For a pound of bricks with a density of 2.5 g/cm³, the volume would be:\n",
      "\n",
      "1 pound = 453.59 grams\n",
      "453.59 grams / 2.5 g/cm³ = approximately 181.38 cm³\n",
      "\n",
      "As we can see, a pound of feathers would occupy a volume of about 5049 cm³, while a pound of bricks would occupy a volume of about 181.38 cm³. This difference in volume is due to the difference in density between feathers and bricks.\n",
      "\n",
      "So, to summarize, a pound of feathers and a pound of bricks weigh the same, 1 pound, but the feather takes up much more space than the brick due to its lower density.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We can pass our own history to the ask method\n",
    "# You can use as many dictionaries as you want in the history list but each one will add tokens to the request\n",
    "history = [\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "    {\"role\": \"assistant\", \"content\": new_answer['response']}\n",
    "]\n",
    "\n",
    "# Here we change the context to a college professor and pass our chat history\n",
    "params = {\n",
    "    \"temperature\": 0.9, \n",
    "    \"max_new_tokens\": 200,\n",
    "    \"context\": \"You are college professor who provides complex answers backed by science.\",\n",
    "    \"history\": history\n",
    "}\n",
    "\n",
    "# Our new question references the chat history\n",
    "new_question = \"Can you explain your previous answer in more detail?\"\n",
    "\n",
    "new_answer = llama3_model.ask(new_question, params)\n",
    "\n",
    "print(new_answer['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VectorEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ai_server import VectorEngine\n",
    "\n",
    "# Using a FAISS vector engine\n",
    "vector_engine_id = os.getenv('DEV_VECTOR_ENGINE_ID')\n",
    "\n",
    "# We initialize the VectorEngine object with the engine id and the current insight id\n",
    "faiss_vector_engine = VectorEngine(engine_id=vector_engine_id, insight_id=server_connection.cur_insight)\n",
    "\n",
    "file_path = \"./ai-whitehouse.pdf\"\n",
    "\n",
    "# We can add documents to the faiss index with the addDocument method\n",
    "faiss_vector_engine.addDocument(file_paths = [file_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing uploaded documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fileName': 'constitution.pdf', 'fileSize': 404.2470703125, 'lastModified': '2025-03-21 16:18:35'}, {'fileName': 'ai-whitehouse.pdf', 'fileSize': 578.16015625, 'lastModified': '2025-03-25 13:16:53'}]\n"
     ]
    }
   ],
   "source": [
    "# Fetch a list of uploaded documents\n",
    "my_documents = faiss_vector_engine.listDocuments()\n",
    "\n",
    "print(my_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a nearest neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1\n",
      "SCORE: 0.7842901945114136\n",
      "TOKENS: 165\n",
      "CONTENT: information, such as images, videos, audio clips, and text, that has been significantly modified or generated by algorithms, including by AI. (ff ) The term “testbed” means a facility or mechanism equipped for conducting rigorous, transparent, and replicable testing of tools and 11/15/23, 10:36 AM Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence | The White House https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-u… 10/63 technologies, including AI and PETs, to help evaluate the functionality, usability, and performance of those tools or technologies.\n",
      "Result 2\n",
      "SCORE: 0.7212825417518616\n",
      "TOKENS: 164\n",
      "CONTENT: of Artificial Intelligence | The White House https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-us… 6/63 manner; and use model inference to formulate options for information or action. (c) The term “AI model” means a component of an information system that implements AI technology and uses computational, statistical, or machine-learning techniques to produce outputs from a given set of inputs. (d) The term “AI red-teaming” means a structured testing effort to find flaws and vulnerabilities in an AI system, often in a controlled environment and in collaboration with developers of AI. Artificial Intelligence red- teaming\n",
      "Result 3\n",
      "SCORE: 0.6118261814117432\n",
      "TOKENS: 140\n",
      "CONTENT: term “Intelligence Community” has the meaning given to that term in section 3.5(h) of Executive Order 12333 of December 4, 1981 (United States Intelligence Activities), as amended. (t) The term “machine learning” means a set of techniques that can be used to train AI algorithms to improve performance at a task based on data. (u) The term “model weight” means a numerical parameter within an AI model that helps determine the model’s outputs in response to inputs. (v) The term “national security system” has the meaning set forth in 44 U.S.C. 3552(b)(6). (w) The\n"
     ]
    }
   ],
   "source": [
    "query = \"How does the document define machine learning?\"\n",
    "\n",
    "# Find the closest match(es) between the question bassed in and the embedded documents using Euclidena Distance.\n",
    "nearest_neighbor = faiss_vector_engine.nearestNeighbor(search_statement=query, limit = 3, insight_id = server_connection.cur_insight)\n",
    "\n",
    "for index, result in enumerate(nearest_neighbor):\n",
    "    print(f\"Result {index + 1}\")\n",
    "    print(f\"SCORE: {result['Score']}\")\n",
    "    print(f\"TOKENS: {result['Tokens']}\")\n",
    "    print(f\"CONTENT: {result['Content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'fileName': 'constitution.pdf', 'fileSize': 404.2470703125, 'lastModified': '2025-03-21 16:18:35'}]\n"
     ]
    }
   ],
   "source": [
    "# Names of the files we want to remove\n",
    "file_names = ['ai-whitehouse.pdf']\n",
    "\n",
    "faiss_vector_engine.removeDocument(file_names = file_names)\n",
    "\n",
    "print(faiss_vector_engine.listDocuments())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DatabaseEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LOCATION HEIGHT WEIGHT\n",
      "0  Buckingham     61    256\n",
      "1         Bjc     60    220\n",
      "2      Louisa     61    203\n",
      "3      Louisa     59    204\n",
      "4      Louisa     61    220\n",
      "5      Louisa     58    210\n"
     ]
    }
   ],
   "source": [
    "from ai_server import DatabaseEngine\n",
    "\n",
    "# An example H2 diabetes database\n",
    "db_engine_id = os.getenv('DEV_DATABASE_ENGINE_ID')\n",
    "\n",
    "# Connect to the database by passing the engine id and the current insight id\n",
    "db = DatabaseEngine(engine_id=db_engine_id, insight_id=server_connection.cur_insight)\n",
    "\n",
    "query = db.execQuery(query = \"SELECT height, weight, location FROM diabetes WHERE height < 62 AND weight > 200\")\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inserting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "User does not have permission to exec query for this app",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m insert = \u001b[33m\"\u001b[39m\u001b[33mINSERT INTO diabetes (height, weight, location) VALUES (65, 200, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mRosslyn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# NOTE you will need to be an author or editor of the database to insert or delete data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43minsertData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minsert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m query = db.execQuery(query = \u001b[33m\"\u001b[39m\u001b[33mSELECT height, weight, location FROM diabetes WHERE location = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mRosslyn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\ai_server\\py_client\\gaas\\database.py:87\u001b[39m, in \u001b[36mDatabaseEngine.insertData\u001b[39m\u001b[34m(self, query, insight_id, commit)\u001b[39m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34minsertData\u001b[39m(\n\u001b[32m     77\u001b[39m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, insight_id: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, commit: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     78\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     79\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    Connect to a database an execute SQL against it to insert data\u001b[39;00m\n\u001b[32m     81\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m \u001b[33;03m        commit (`bool`): commit to the database if autocommit is false. default is true\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsight_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\ai_server\\py_client\\gaas\\database.py:133\u001b[39m, in \u001b[36mDatabaseEngine.runQuery\u001b[39m\u001b[34m(self, query, insight_id, commit)\u001b[39m\n\u001b[32m    129\u001b[39m commitStr = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m commit \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfalse\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m pixel = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDatabase(database = \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.engine_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m)|Query(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<encode>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</encode>\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)|ExecQuery(commit=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommitStr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m);\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m output_payload_message = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pixel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsight_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43minsight_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_response\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_payload_message[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moperationType\u001b[39m\u001b[33m\"\u001b[39m] == [\u001b[33m\"\u001b[39m\u001b[33mERROR\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(output_payload_message[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\ai_server\\server_resources\\server_client.py:269\u001b[39m, in \u001b[36mServerClient.run_pixel\u001b[39m\u001b[34m(self, payload, insight_id, full_response)\u001b[39m\n\u001b[32m    267\u001b[39m logger.info(response_dict)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mERROR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response_dict[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moperationType\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(response_dict[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_response:\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_dict\n",
      "\u001b[31mException\u001b[39m: User does not have permission to exec query for this app"
     ]
    }
   ],
   "source": [
    "insert = \"INSERT INTO diabetes (height, weight, location) VALUES (65, 200, 'Rosslyn')\"\n",
    "\n",
    "# NOTE you will need to be an author or editor of the database to insert or delete data\n",
    "db.insertData(query = insert)\n",
    "\n",
    "query = db.execQuery(query = \"SELECT height, weight, location FROM diabetes WHERE location = 'Rosslyn'\")\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "User does not have permission to exec query for this app",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m remove = \u001b[33m\"\u001b[39m\u001b[33mDELETE FROM diabetes WHERE location = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mRosslyn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremoveData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m query = db.execQuery(query = \u001b[33m\"\u001b[39m\u001b[33mSELECT height, weight, location FROM diabetes WHERE location = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mRosslyn\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\ai_server\\py_client\\gaas\\database.py:113\u001b[39m, in \u001b[36mDatabaseEngine.removeData\u001b[39m\u001b[34m(self, query, insight_id, commit)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mremoveData\u001b[39m(\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, insight_id: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m, commit: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    104\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    105\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    Connect to a database an execute SQL against it to delete/remove data\u001b[39;00m\n\u001b[32m    107\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m \u001b[33;03m        commit (`bool`): commit to the database if autocommit is false. default is true\u001b[39;00m\n\u001b[32m    112\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrunQuery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsight_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\ai_server\\py_client\\gaas\\database.py:133\u001b[39m, in \u001b[36mDatabaseEngine.runQuery\u001b[39m\u001b[34m(self, query, insight_id, commit)\u001b[39m\n\u001b[32m    129\u001b[39m commitStr = \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m commit \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfalse\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m pixel = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mDatabase(database = \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.engine_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m)|Query(\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m<encode>\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m</encode>\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m)|ExecQuery(commit=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcommitStr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m);\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m output_payload_message = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pixel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsight_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43minsight_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_response\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    135\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_payload_message[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moperationType\u001b[39m\u001b[33m\"\u001b[39m] == [\u001b[33m\"\u001b[39m\u001b[33mERROR\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(output_payload_message[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\ai_server\\server_resources\\server_client.py:269\u001b[39m, in \u001b[36mServerClient.run_pixel\u001b[39m\u001b[34m(self, payload, insight_id, full_response)\u001b[39m\n\u001b[32m    267\u001b[39m logger.info(response_dict)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mERROR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response_dict[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moperationType\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(response_dict[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_response:\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_dict\n",
      "\u001b[31mException\u001b[39m: User does not have permission to exec query for this app"
     ]
    }
   ],
   "source": [
    "remove = \"DELETE FROM diabetes WHERE location = 'Rosslyn'\"\n",
    "\n",
    "db.removeData(query = remove)\n",
    "\n",
    "query = db.execQuery(query = \"SELECT height, weight, location FROM diabetes WHERE location = 'Rosslyn'\")\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FunctionEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "prerna.engine.impl.storage.S3StorageEngine cannot be cast to prerna.engine.api.IFunctionEngine",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m function = FunctionEngine(engine_id=weather_id, insight_id=server_connection.cur_insight)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Parameters will change based on the function you are using\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m output = \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlat\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m37.540\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlon\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m77.4360\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\ai_server\\py_client\\gaas\\function.py:31\u001b[39m, in \u001b[36mFunctionEngine.execute\u001b[39m\u001b[34m(self, parameterMap, insight_id)\u001b[39m\n\u001b[32m     25\u001b[39m     insight_id = \u001b[38;5;28mself\u001b[39m.insight_id\n\u001b[32m     27\u001b[39m pixel = (\n\u001b[32m     28\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mExecuteFunctionEngine(engine = \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.engine_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m, map=[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparameterMap\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]);\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m output_payload_message = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_pixel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minsight_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43minsight_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_response\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     33\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_payload_message[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moperationType\u001b[39m\u001b[33m\"\u001b[39m] == [\u001b[33m\"\u001b[39m\u001b[33mERROR\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(output_payload_message[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danmoreno\\.pyenv\\pyenv-win\\versions\\3.11.9\\Lib\\site-packages\\ai_server\\server_resources\\server_client.py:269\u001b[39m, in \u001b[36mServerClient.run_pixel\u001b[39m\u001b[34m(self, payload, insight_id, full_response)\u001b[39m\n\u001b[32m    267\u001b[39m logger.info(response_dict)\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mERROR\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response_dict[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moperationType\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m269\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(response_dict[\u001b[33m\"\u001b[39m\u001b[33mpixelReturn\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33moutput\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m full_response:\n\u001b[32m    272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_dict\n",
      "\u001b[31mException\u001b[39m: prerna.engine.impl.storage.S3StorageEngine cannot be cast to prerna.engine.api.IFunctionEngine"
     ]
    }
   ],
   "source": [
    "from ai_server import FunctionEngine\n",
    "\n",
    "# Weather function engine\n",
    "weather_id = os.getenv('DEV_FUNCTION_ENGINE_ID')\n",
    "\n",
    "function = FunctionEngine(engine_id=weather_id, insight_id=server_connection.cur_insight)\n",
    "\n",
    "# Parameters will change based on the function you are using\n",
    "output = function.execute({\"lat\":\"37.540\",\"lon\":\"77.4360\"})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StorageEngine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- machine-readable-business-employment-data-mar-2024-quarter.csv\n",
      "-- version/\n",
      "-- {'Path': 'machine-readable-business-employment-data-mar-2024-quarter.csv', 'Name': 'machine-readable-business-employment-data-mar-2024-quarter.csv', 'Size': 3583192.0, 'MimeType': 'text/csv; charset=utf-8', 'ModTime': '2024-06-13T19:11:49.768746813Z', 'IsDir': False, 'Tier': 'STANDARD', 'Metadata': {'atime': '2024-06-13T19:11:49.768746813Z', 'btime': '2024-11-01T21:28:04Z', 'content-type': 'text/csv; charset=utf-8', 'gid': '0', 'mode': '100640', 'mtime': '2024-06-13T19:11:49.768746813Z', 'tier': 'STANDARD', 'uid': '0'}}\n",
      "-- {'Path': 'version', 'Name': 'version', 'Size': 0.0, 'MimeType': 'inode/directory', 'ModTime': '2000-01-01T00:00:00.000000000Z', 'IsDir': True}\n"
     ]
    }
   ],
   "source": [
    "from ai_server import StorageEngine\n",
    "\n",
    "# Example S3 bucket\n",
    "storage_engine_id = os.getenv('DEV_STORAGE_ENGINE_ID')\n",
    "\n",
    "storageEngine = StorageEngine(engine_id = storage_engine_id, insight_id = server_connection.cur_insight)\n",
    "\n",
    "s3_storage_path = \"/my-new-test-folder/\"\n",
    "\n",
    "# A list of the files in the given path\n",
    "my_dir = storageEngine.list(storagePath = s3_storage_path)\n",
    "\n",
    "for file in my_dir:\n",
    "    print (f\"-- {file}\")\n",
    "\n",
    "# A list of details about the files in the given path\n",
    "my_dir_details = storageEngine.listDetails(storagePath = '/my-new-test-folder/')\n",
    "\n",
    "for file_details in my_dir_details:\n",
    "    print (f\"-- {file_details}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Response --\n",
      "2\n",
      "Full Response --\n",
      "{'insightID': 'f6839fb0-e65d-4cff-b539-821f72434c1d', 'pixelReturn': [{'pixelId': '27', 'pixelExpression': '1 + 1 ;', 'isMeta': False, 'timeToRun': 2, 'output': 2, 'operationType': ['OPERATION']}]}\n"
     ]
    }
   ],
   "source": [
    "# You can use the active server connection to run pixels\n",
    "\n",
    "simple_pixel_response = server_connection.run_pixel('1+1')\n",
    "\n",
    "print('Simple Response --')\n",
    "print(simple_pixel_response)\n",
    "\n",
    "full_pixel_response = server_connection.run_pixel('1+1', full_response=True)\n",
    "\n",
    "print('Full Response --')\n",
    "print(full_pixel_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Chat with pixels example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'numberOfTokensInResponse': 6, 'numberOfTokensInPrompt': 136, 'response': 'The capital of Connecticut is Hartford.', 'messageId': 'cd299520-acf0-45a9-b02c-6c5d09c3a213', 'roomId': 'f6839fb0-e65d-4cff-b539-821f72434c1d'}\n"
     ]
    }
   ],
   "source": [
    "engine_id = os.getenv('DEV_LLM_CHAT_ENGINE_ID')\n",
    "\n",
    "chat = server_connection.run_pixel(\n",
    "    f\"LLM ( engine = [ '{engine_id}' ] , command = [ '<encode>What is the capital of Connecticut</encode>' ] , paramValues = [ {{ 'max_new_tokens' : 200 , 'temperature' : 0.3 }} ] )\"\n",
    ")\n",
    "print(chat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
